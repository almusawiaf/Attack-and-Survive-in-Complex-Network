{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e62d30",
   "metadata": {},
   "source": [
    "# Percolation analysis\n",
    "\n",
    "* read a network\n",
    "* drop the links\n",
    "* add links based on some measure (for example, link weight)\n",
    "\n",
    "* we measure on scale (0-1) how quickly they make a one complete component\n",
    "* Percolation = |N_LCC|/|N|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f35cbec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "standard networks dataset\\dolphins\\dolphins.gml\n",
      "standard networks dataset\\polbooks\\out2.txt\n",
      "standard networks dataset\\word_adjacencies.gml\\word_adjacencies.gml\n",
      "standard networks dataset\\arenas-email\\out2.txt\n",
      "standard networks datasetKarate\n",
      "standard networks datasetErdos Renyi\n",
      "standard networks dataset\\USAir97\\USAir97.mtx\n",
      "standard networks dataset\\circuits\\s208_st.txt\n",
      "standard networks dataset\\circuits\\s420_st.txt\n",
      "standard networks dataset\\circuits\\s838_st.txt\n",
      "standard networks dataset\\E. Coli\\E. Coli.txt\n",
      "standard networks datasetBarabasi_albert_graph\n",
      "standard networks dataset\\facebook\\0.edges\n",
      "standard networks dataset\\facebook\\107.edges\n",
      "standard networks dataset\\facebook\\348.edges\n",
      "standard networks dataset\\facebook\\414.edges\n",
      "standard networks dataset\\facebook\\686.edges\n",
      "standard networks dataset\\facebook\\1684.edges\n",
      "standard networks dataset\\bio-celegans\\bio-celegans.mtx\n",
      "standard networks dataset\\bn-macaque-rhesus_brain_2\\bn-macaque-rhesus_brain_2.txt\n",
      "standard networks dataset\\soc-tribes\\soc-tribes.txt\n",
      "standard networks dataset\\fb-pages-food\\fb-pages-food.txt\n",
      "standard networks dataset\\bn-cat-mixed-species_brain_1\\bn-cat-mixed-species_brain_1.txt\n",
      "standard networks dataset\\ca-sandi_auths\\ca-sandi_auths.mtx\n",
      "standard networks dataset\\soc-firm-hi-tech\\soc-firm-hi-tech.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import networkx as nx\n",
    "import os\n",
    "from DA import pls_da1\n",
    "datasets = [\"\\dolphins\\dolphins.gml\",\n",
    "            \"\\polbooks\\out2.txt\",\n",
    "            \"\\word_adjacencies.gml\\word_adjacencies.gml\",\n",
    "            \"\\\\arenas-email\\\\out2.txt\",\n",
    "            \"Karate\",\n",
    "            \"Erdos Renyi\",\n",
    "            \"\\\\USAir97\\\\USAir97.mtx\", \n",
    "            \"\\\\circuits\\s208_st.txt\",\n",
    "            \"\\\\circuits\\s420_st.txt\",\n",
    "            \"\\\\circuits\\s838_st.txt\",\n",
    "            \"\\\\E. Coli\\E. Coli.txt\",\n",
    "            \"Barabasi_albert_graph\",\n",
    "            \"\\\\facebook\\\\0.edges\",\n",
    "            \"\\\\facebook\\\\107.edges\",\n",
    "            \"\\\\facebook\\\\348.edges\",\n",
    "            \"\\\\facebook\\\\414.edges\",\n",
    "            \"\\\\facebook\\\\686.edges\",\n",
    "            \"\\\\facebook\\\\1684.edges\",\n",
    "            \"\\\\bio-celegans\\\\bio-celegans.mtx\",\n",
    "            \"\\\\bn-macaque-rhesus_brain_2\\\\bn-macaque-rhesus_brain_2.txt\",\n",
    "            '\\\\soc-tribes\\\\soc-tribes.txt',\n",
    "            '\\\\fb-pages-food\\\\fb-pages-food.txt',\n",
    "            '\\\\bn-cat-mixed-species_brain_1\\\\bn-cat-mixed-species_brain_1.txt',\n",
    "            '\\\\ca-sandi_auths\\\\ca-sandi_auths.mtx',\n",
    "            '\\\\soc-firm-hi-tech\\\\soc-firm-hi-tech.txt']\n",
    "\n",
    "def read_graph2(g):\n",
    "    file_name = 'standard networks dataset' + datasets[int(g)]\n",
    "    print(file_name)\n",
    "    G = nx.Graph()\n",
    "    if g==4:\n",
    "        G = nx.karate_club_graph()\n",
    "    elif g==5:\n",
    "        # nodes = int(input(\"enter number of nodes?\"))\n",
    "        # edges= int(input(\"enter number of edges?\"))\n",
    "        G = nx.gnm_random_graph(500, 1500)\n",
    "    elif g==11:\n",
    "        # nodes = int(input(\"enter number of nodes?\"))\n",
    "        # edges= int(input(\"enter number of edges?\"))\n",
    "        # p = int(input(\"enter P value?\"))\n",
    "        G = nx.barabasi_albert_graph(500, 3)\n",
    "    else:\n",
    "        ext = os.path.splitext(file_name)[1]\n",
    "        if ext=='.edges':\n",
    "            G = nx.read_adjlist(file_name, create_using = nx.Graph(), nodetype = int)\n",
    "        elif ext=='.gml':\n",
    "            G = nx.read_gml(file_name)\n",
    "        elif ext=='.mtx':\n",
    "            G = None\n",
    "            #matrix = scipy.io.mmread(file_name)\n",
    "            #G = nx.from_scipy_sparse_matrix(matrix)\n",
    "        elif ext=='.txt':\n",
    "            file = open(file_name, 'r')\n",
    "            lines=  file.readlines()\n",
    "            G = nx.Graph()\n",
    "            for line in lines:\n",
    "                if \" \" in line:\n",
    "                    N = line.split(\" \")\n",
    "                else:\n",
    "                    N = line.split(\"\\t\")\n",
    "                G.add_edge(N[0], N[1])\n",
    "    return G\n",
    "\n",
    "# read the networks\n",
    "networks = {}\n",
    "for net in range(len(datasets)):\n",
    "    g = read_graph2(net)\n",
    "    if g:\n",
    "        networks[datasets[net]] = g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c19fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['dolphins',\n",
    " 'polbooks',\n",
    " 'word_adjacencies',\n",
    " 'arenas-email',\n",
    " 'Karate',\n",
    " 'Erdos Renyi',\n",
    " 'circuits s208_st',\n",
    " 'circuits s420_st',\n",
    " 'circuits s838_st',\n",
    " 'E. Coli',\n",
    " 'Barabasi_albert_graph',\n",
    " 'facebook0',\n",
    " 'facebook107',\n",
    " 'facebook348',\n",
    " 'facebook414',\n",
    " 'facebook686',\n",
    " 'facebook1684',\n",
    " 'bn-macaque-rhesus_brain_2',\n",
    " 'soc-tribes',\n",
    " 'fb-pages-food',\n",
    " 'bn-cat-mixed-species_brain_1',\n",
    " 'soc-firm-hi-tech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2908a11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def properties(G):\n",
    "    GCC = nx.transitivity(G)\n",
    "    ACC = nx.average_clustering(G)\n",
    "    d = nx.density(G)\n",
    "    r = nx.degree_assortativity_coefficient(G)    \n",
    "    lcg = sorted(nx.connected_components(G), key=len, reverse=True)\n",
    "    LCG = G.subgraph(lcg[0])    \n",
    "    ASP = nx.average_shortest_path_length(LCG)\n",
    "    diam = nx.diameter(LCG)\n",
    "    return  GCC, ACC, d, r, ASP, diam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8f8999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_edges(G, C):\n",
    "    '''return a weighted edges'''\n",
    "    W = []\n",
    "    for u,v in G.edges():\n",
    "        W.append([u, v, C[u]*C[v]])\n",
    "    return sorted(W, key=lambda x: x[2])\n",
    "\n",
    "def batch_list(lst):\n",
    "    \"\"\"\n",
    "    Divide a list into batches of an equal number of items (as close to 50 as possible).\n",
    "    \"\"\"\n",
    "    batch_size = (len(lst) + 49) // 50  # Calculate the batch size\n",
    "    num_batches = (len(lst) + batch_size - 1) // batch_size\n",
    "    batches = [lst[i*batch_size:(i+1)*batch_size] for i in range(num_batches)]\n",
    "    return batches\n",
    "\n",
    "def simulation(centr):\n",
    "    results = []\n",
    "    for network in networks.keys():\n",
    "        print(network)\n",
    "        G0 = networks[network]\n",
    "        bc_G0 = centr(G0)\n",
    "        W = weighted_edges(G0, bc_G0)\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(G0.nodes())\n",
    "        batches = batch_list(W)\n",
    "\n",
    "        result = []\n",
    "        for b in range(len(batches)):\n",
    "            for u,v,_ in batches[b]:\n",
    "                G.add_edge(u, v)\n",
    "            largest_component = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "            result.append([b, len(largest_component)/len(G)])\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8317038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(results, title):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig = plt.figure(dpi=600)\n",
    "    fig, ax = plt.subplots()\n",
    "    markers = ['+', 'x', 'o', 's', 'd', 'D', '*'] # Add your desired markers here\n",
    "    for d in range(len(results)):\n",
    "        data = results[d]\n",
    "        x = [item[0] for item in data]\n",
    "        y = [item[1] for item in data]\n",
    "        marker_idx = d % len(markers) # Choose marker based on index of the result\n",
    "        ax.plot(x, y, marker=markers[marker_idx], linewidth=0.5, markersize=3, label=name[d])\n",
    "\n",
    "    ax.set_xlabel('edges')\n",
    "    ax.set_ylabel(r'$|N_{LCC}| / |N| $')\n",
    "    ax.set_title(f'{title}-based weighted edges')\n",
    "    plt.legend()\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee9c96e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "centralities = [nx.degree_centrality, nx.betweenness_centrality, nx.closeness_centrality, nx.clustering]\n",
    "centr        = ['Degree'            ,   'Betweenness'          ,   'Closeness'          ,   'Clustering']\n",
    "sims = {}\n",
    "for i in range(4):\n",
    "    cent = centr[i]\n",
    "    sims[cent] = simulation(centralities[i])\n",
    "    plot(sims[cent], cent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c2a55c",
   "metadata": {},
   "source": [
    "# Predicting robustness of networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f8ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R = {}\n",
    "R['Networks'] = name\n",
    "for c in centr:\n",
    "    Rs = []\n",
    "    for i in range(22):\n",
    "        S = sims[c][i]\n",
    "        T, V = 0, 0\n",
    "        for t, v in S:\n",
    "            if v > V:\n",
    "                T = t\n",
    "                V = v\n",
    "        Rs.append(T)\n",
    "    R[c] = Rs\n",
    "pd.DataFrame(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9541e3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_sim():\n",
    "    results = []\n",
    "    for network in networks.keys():\n",
    "        G0 = networks[network]\n",
    "        W = batch_list(list(G0.edges()))\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(G0.nodes())\n",
    "        batches = batch_list(W)\n",
    "\n",
    "        result = []\n",
    "        for b in range(len(batches)):\n",
    "            for (u,v) in batches[b][0]:\n",
    "                G.add_edge(u, v)\n",
    "            largest_component = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "            result.append([b, len(largest_component)/len(G)])\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "plot(random_sim(), 'Random')\n",
    "sims_rnd = random_sim()\n",
    "\n",
    "Rs = []\n",
    "for i in range(22):\n",
    "    S = sims_rnd[i]\n",
    "    T, V = 0, 0\n",
    "    for t, v in S:\n",
    "        if v > V:\n",
    "            T = t\n",
    "            V = v\n",
    "    Rs.append(T)\n",
    "R['Random'] = Rs\n",
    "pd.DataFrame(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4334149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulation2():\n",
    "    '''Implementing reverse preferential attachment'''\n",
    "    results = []\n",
    "    k = 0.01\n",
    "    for network in networks.keys():\n",
    "        print(network)\n",
    "        G0 = networks[network]\n",
    "        d = nx.degree_centrality(G0)\n",
    "        W = [[u, v, (1/((d[u]+k)*(d[v]+k)))] for u,v in G0.edges()]\n",
    "        W = sorted(W, key=lambda x: x[2])\n",
    "        G = nx.Graph()\n",
    "        G.add_nodes_from(G0.nodes())\n",
    "        batches = batch_list(W)\n",
    "\n",
    "        result = []\n",
    "        for b in range(len(batches)):\n",
    "            for u,v,_ in batches[b]:\n",
    "                G.add_edge(u, v)\n",
    "            largest_component = G.subgraph(max(nx.connected_components(G), key=len))\n",
    "            result.append([b, len(largest_component)/len(G)])\n",
    "        results.append(result)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e16e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(simulation2(), 'Inverted PA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb08a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims_rnd = simulation2()\n",
    "\n",
    "Rs = []\n",
    "for i in range(22):\n",
    "    S = sims_rnd[i]\n",
    "    T, V = 0, 0\n",
    "    for t, v in S:\n",
    "        if v > V:\n",
    "            T = t\n",
    "            V = v\n",
    "    Rs.append(T)\n",
    "R['Inverted PA'] = Rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f9ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_properties = [properties(networks[g]) for g in networks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef944ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "GCCs = [i for i, _,_,_,_,_ in network_properties]\n",
    "ACCs = [i for _, i,_,_,_,_ in network_properties]\n",
    "ds   = [i for _, _,i,_,_,_ in network_properties]\n",
    "rs   = [i for _, _,_,i,_,_ in network_properties]\n",
    "ASPs = [i for _, _,_,_,i,_ in network_properties]\n",
    "diam = [i for _, _,_,_,_,i in network_properties]\n",
    "\n",
    "df2 = pd.DataFrame({'Networks': name, 'GCC': GCCs, 'ACC': ACCs, 'Density': ds, 'r': rs, 'ASP': ASPs, 'Diameter': diam}) \n",
    "df2.to_csv('Data/networks properties.csv', index=False)\n",
    "\n",
    "\n",
    "numeric_cols = df2.select_dtypes(include='number').columns\n",
    "df_quartiles = df2[numeric_cols].apply(lambda x: pd.qcut(x.dropna(), q=[0, 0.25, 0.5, 0.75, 1.0], labels=[0.25,0.5,0.75,1]) if x.dtype != object else x)\n",
    "df_quartiles['Networks'] = df2['Networks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9350140",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(R)\n",
    "\n",
    "medians = df1.median()\n",
    "print(medians)\n",
    "for column in df1.columns :\n",
    "    if column!= 'Networks':\n",
    "        median = medians[column]  # Retrieve the median for the column\n",
    "        df1[column] = (df1[column] < median).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c7ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset = pd.merge(df_quartiles, df1, on='Networks')\n",
    "Dataset = Dataset.reindex(columns = ['Networks', 'GCC', 'ACC', 'Density', 'r', 'ASP', 'Diameter', 'Degree',\n",
    "       'Betweenness', 'Closeness', 'Clustering', 'Random', 'Inverted PA'])\n",
    "Dataset.to_csv('Data/velnerability output.csv', index=False)\n",
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40b890ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Degree': [[0.051596228416095784],\n",
       "  [0.028769530557538423],\n",
       "  [0.13368620135899473],\n",
       "  [-0.04513237612424448],\n",
       "  [-0.15557727792904194],\n",
       "  [-0.1081763931154136]],\n",
       " 'Betweenness': [[-0.0549023376778545],\n",
       "  [-0.031102568213353877],\n",
       "  [-0.005048550742868397],\n",
       "  [-0.12076364934178835],\n",
       "  [-0.10942195475126394],\n",
       "  [-0.13762176619504451]],\n",
       " 'Closeness': [[0.22810638836118072],\n",
       "  [0.20442391971557453],\n",
       "  [0.08364138884258178],\n",
       "  [-0.013502421632581547],\n",
       "  [0.004621882589407485],\n",
       "  [0.011787688499881438]],\n",
       " 'Clustering': [[0.017796285664701407],\n",
       "  [0.05117195642483444],\n",
       "  [0.05398307933296709],\n",
       "  [-0.11578336574465273],\n",
       "  [-0.06939954360897169],\n",
       "  [-0.04647790023406552]],\n",
       " 'Random': [[0.006858683168286773],\n",
       "  [0.04543108025056324],\n",
       "  [-0.02547456977560801],\n",
       "  [-0.06195294527120876],\n",
       "  [-0.06945532594653794],\n",
       "  [-0.09703895094773181]],\n",
       " 'Inverted PA': [[0.1258261921783094],\n",
       "  [0.20338553059341027],\n",
       "  [-0.041482604988132964],\n",
       "  [-0.2918435837437639],\n",
       "  [0.019395419045435295],\n",
       "  [-0.15441403298776332]]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('Data/velnerability output.csv')\n",
    "oldR = {}\n",
    "X = data.loc[:, ['GCC', 'ACC', 'Density', 'r', 'ASP', 'Diameter']]\n",
    "for c in [ 'Degree', 'Betweenness', 'Closeness', 'Clustering', 'Random', 'Inverted PA']:\n",
    "    Y = data[c]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=19)\n",
    "    oldR[c] = pls_da1(X_train, y_train, X_test).tolist()\n",
    "\n",
    "oldR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe75a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Degree</th>\n",
       "      <th>Betweenness</th>\n",
       "      <th>Closeness</th>\n",
       "      <th>Clustering</th>\n",
       "      <th>Random</th>\n",
       "      <th>Inverted PA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051596</td>\n",
       "      <td>-0.054902</td>\n",
       "      <td>0.228106</td>\n",
       "      <td>0.017796</td>\n",
       "      <td>0.006859</td>\n",
       "      <td>0.125826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.028770</td>\n",
       "      <td>-0.031103</td>\n",
       "      <td>0.204424</td>\n",
       "      <td>0.051172</td>\n",
       "      <td>0.045431</td>\n",
       "      <td>0.203386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133686</td>\n",
       "      <td>-0.005049</td>\n",
       "      <td>0.083641</td>\n",
       "      <td>0.053983</td>\n",
       "      <td>-0.025475</td>\n",
       "      <td>-0.041483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.045132</td>\n",
       "      <td>-0.120764</td>\n",
       "      <td>-0.013502</td>\n",
       "      <td>-0.115783</td>\n",
       "      <td>-0.061953</td>\n",
       "      <td>-0.291844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.155577</td>\n",
       "      <td>-0.109422</td>\n",
       "      <td>0.004622</td>\n",
       "      <td>-0.069400</td>\n",
       "      <td>-0.069455</td>\n",
       "      <td>0.019395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.108176</td>\n",
       "      <td>-0.137622</td>\n",
       "      <td>0.011788</td>\n",
       "      <td>-0.046478</td>\n",
       "      <td>-0.097039</td>\n",
       "      <td>-0.154414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Degree  Betweenness  Closeness  Clustering    Random  Inverted PA\n",
       "0  0.051596    -0.054902   0.228106    0.017796  0.006859     0.125826\n",
       "1  0.028770    -0.031103   0.204424    0.051172  0.045431     0.203386\n",
       "2  0.133686    -0.005049   0.083641    0.053983 -0.025475    -0.041483\n",
       "3 -0.045132    -0.120764  -0.013502   -0.115783 -0.061953    -0.291844\n",
       "4 -0.155577    -0.109422   0.004622   -0.069400 -0.069455     0.019395\n",
       "5 -0.108176    -0.137622   0.011788   -0.046478 -0.097039    -0.154414"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = {c: [i[0] for i in oldR[c]] for c in oldR}\n",
    "pd.DataFrame(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abce153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
